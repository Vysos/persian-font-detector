{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21AczAd4lKYq"
      },
      "source": [
        "## Importing files and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPPKWiVwu4Jl"
      },
      "outputs": [],
      "source": [
        "!gdown 12Z1bFBPRsEYFswdEMGzyTnthL4xEdZl-\n",
        "!unrar x /content/images.rar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DG1AxbjQvZos"
      },
      "outputs": [],
      "source": [
        "!mkdir images\n",
        "!mv ./test ./images/test\n",
        "!mv ./validation ./images/validation\n",
        "!mv ./train ./images/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "APHXSzLcvdYT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import copy\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import shutil\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu8GREYfgp4-"
      },
      "source": [
        "## Preproceesing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KepAC5ZrzuuS"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWV3P7Uwz8U-",
        "outputId": "ac18c8b1-4b36-49d5-e245-e48338339d4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"./images\"\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'validation', 'test']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'validation', 'test']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ggSzNtaY0FIX"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class_names = image_datasets['train'].classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsPelnDFgmpO"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zRhHmwwS0HOX"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    model.to(device)\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_corrects = 0\n",
        "\n",
        "        for inputs, labels in tqdm(dataloaders['train'], total=len(dataloaders['train'])):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            train_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        train_loss = train_loss / len(image_datasets['train'])\n",
        "        train_acc = train_corrects.double() / len(image_datasets['train'])\n",
        "        print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.2%}')\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "\n",
        "        for inputs, labels in tqdm(dataloaders['validation'], total=len(dataloaders['validation'])):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.set_grad_enabled(False):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_loss = val_loss / len(image_datasets['validation'])\n",
        "        val_acc = val_corrects.double() / len(image_datasets['validation'])\n",
        "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.2%}')\n",
        "\n",
        "        # Check if current model has the best validation accuracy\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    print(f'Best val Acc: {best_acc:.2%}')\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8mygACw0QHw",
        "outputId": "a70bf4f6-fba8-4c3a-9a4a-e7387d6bcc3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
        "num_classes = len(class_names)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCxU5k_J0R6P",
        "outputId": "a71e61ff-7d78-4bec-ba2b-7035b75ae10b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13771/13771 [20:13<00:00, 11.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2035 Acc: 93.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1722/1722 [00:48<00:00, 35.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.0130 Acc: 99.49%\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13771/13771 [20:19<00:00, 11.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0216 Acc: 99.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1722/1722 [00:50<00:00, 34.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.0253 Acc: 99.26%\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13771/13771 [20:34<00:00, 11.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0123 Acc: 99.62%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1722/1722 [00:51<00:00, 33.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.0034 Acc: 99.91%\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13771/13771 [20:40<00:00, 11.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0093 Acc: 99.74%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1722/1722 [00:50<00:00, 33.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.0095 Acc: 99.81%\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13771/13771 [20:43<00:00, 11.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0066 Acc: 99.83%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1722/1722 [00:50<00:00, 33.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.0066 Acc: 99.78%\n",
            "\n",
            "Best val Acc: 99.91%\n"
          ]
        }
      ],
      "source": [
        "model = train_model(model, criterion, optimizer, scheduler, num_epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6GXwRZygfuy"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xtf18py0Ta_",
        "outputId": "089261d1-021d-4bf4-b77e-06207722363d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9990\n"
          ]
        }
      ],
      "source": [
        "def test_model(model):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in dataloaders['test']:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    test_acc = running_corrects.double() / len(image_datasets['test'])\n",
        "    print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "test_model(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrMZwPRSgZVm"
      },
      "source": [
        "## Test with external Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Miwv8XZH3W",
        "outputId": "0ffdfeb8-e816-46f2-8cea-65d718cf3276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted class: Yasamin\n"
          ]
        }
      ],
      "source": [
        "def test_external_image(model, image_path):\n",
        "    # Load and preprocess the image\n",
        "    image_transforms = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = image_transforms(image)\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    # Move the image tensor to the same device as the model\n",
        "    image = image.to(device)\n",
        "\n",
        "    # Pass the image through the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Get the predicted class index and class name\n",
        "    predicted_class_index = predicted.item()\n",
        "    predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "    # Print the predicted class name\n",
        "    print(f\"Predicted class: {predicted_class_name}\")\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/ccc.jpg\"  # Replace with the path to your image\n",
        "test_external_image(model, image_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHZq_K0cLk1"
      },
      "source": [
        "## Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ivxaMIqWX-LQ"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'new_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGqsA8QOaHdz"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ov0pLAd2aGyC"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the model\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
        "num_classes = len(class_names)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Load the saved model state dictionary\n",
        "model.load_state_dict(torch.load('/content/Trained_ResNet101.pth'))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
